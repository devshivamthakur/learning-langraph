{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c226b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Optional\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2038fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 create stats\n",
    "class EssayInput(TypedDict):\n",
    "    eassy: str # clarity of thought\n",
    "    cot_score: Optional[float]\n",
    "    depth_of_analysis_score: Optional[float]\n",
    "    language_proficiency_score: Optional[float]\n",
    "    average_score: Optional[float]\n",
    "\n",
    "class EssayOutput(BaseModel):\n",
    "    score: float = Field(..., description=\"The overall score of the essay out of 10.\")\n",
    "    \n",
    "#2 create graph with states\n",
    "graph = StateGraph(EssayInput)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75eb6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 create llm instance\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "parser = PydanticOutputParser(pydantic_object=EssayOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d20930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccfaa989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 create nodes function\n",
    "def cot(state: EssayInput):\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "hi you are an expert in UpscEssy . i will provide you an essay evaluation based on clarity of thought.\n",
    "Please provide a score out of 10 based on the clarity of thought in the essay.\n",
    "Essay Evaluation: {eassy}\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "        input_variables=[\"eassy\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    chain = prompt | llm | parser\n",
    "    result = chain.invoke({\n",
    "        \"eassy\": state[\"eassy\"]\n",
    "    })\n",
    "    state[\"cot_score\"] = result.score\n",
    "    return {\"cot_score\": state['cot_score']}\n",
    "\n",
    "def depth_of_analysis(state: EssayInput):\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "hi you are an expert in UpscEssy . i will provide you an essay evaluation based on depth of analysis.\n",
    "Please provide a score out of 10 based on the depth of analysis in the essay. \n",
    "Essay Evaluation: {eassy}\n",
    "{format_instructions}\"\"\",\n",
    "input_variables=['eassy'],\n",
    "partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    chain = prompt | llm | parser\n",
    "    result = chain.invoke({\n",
    "        \"eassy\": state[\"eassy\"]\n",
    "    })\n",
    "    state[\"depth_of_analysis_score\"] = result.score\n",
    "    return {'depth_of_analysis_score': state['depth_of_analysis_score']}\n",
    "\n",
    "def language_proficiency(state: EssayInput):\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "hi you are an expert in UpscEssy . i will provide you an essay evaluation based on language proficiency.\n",
    "Please provide a score out of 10 based on the language proficiency in the essay.\n",
    "Essay Evaluation: {eassy}\n",
    "{format_instructions}\"\"\",\n",
    "input_variables=['eassy'],\n",
    "partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    chain = prompt | llm | parser\n",
    "    result = chain.invoke({\n",
    "        \"eassy\": state[\"eassy\"]\n",
    "    })\n",
    "    state[\"language_proficiency_score\"] = result.score\n",
    "    return {'language_proficiency_score': state['language_proficiency_score']}\n",
    "\n",
    "def average_score(state: EssayInput):\n",
    "    cot_score = state.get(\"cot_score\", 0)\n",
    "    depth_of_analysis_score = state.get(\"depth_of_analysis_score\", 0)\n",
    "    language_proficiency_score = state.get(\"language_proficiency_score\", 0)\n",
    "    average = (cot_score + depth_of_analysis_score + language_proficiency_score) / 3\n",
    "    state[\"average_score\"] = average\n",
    "    return state\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1947f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x26838ce6f90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create nodes\n",
    "\n",
    "graph.add_node(\"clarityOfThought\", cot)\n",
    "graph.add_node(\"depth_of_analysis_node\", depth_of_analysis)\n",
    "graph.add_node(\"language\", language_proficiency)\n",
    "graph.add_node(\"avg\", average_score)\n",
    "\n",
    "\n",
    "#add edges\n",
    "graph.add_edge(START, \"clarityOfThought\")\n",
    "graph.add_edge(START, \"depth_of_analysis_node\")\n",
    "graph.add_edge(START, \"language\")\n",
    "\n",
    "graph.add_edge(\"clarityOfThought\", \"avg\")\n",
    "graph.add_edge(\"depth_of_analysis_node\", \"avg\")\n",
    "graph.add_edge(\"language\", \"avg\")\n",
    "\n",
    "graph.add_edge(\"avg\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae3fa65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = graph.compile()\n",
    "result = workflow.invoke({\n",
    "    \"eassy\": \"Human civilization has always advanced on the pillars of innovation. From the discovery of fire to the invention of the wheel, from industrial machinery to artificial intelligence, technology has consistently shaped the trajectory of human progress. Yet, every leap forward has confronted humanity with new moral dilemmas. Today, as the world enters an era defined by artificial intelligence, biotechnology, quantum computing, and space exploration, the gap between what humanity can do and what it should do has never been wider. The future of humanity will not be determined solely by the pace of technological progress, but by our ability to anchor that progress in ethical responsibility.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc00918c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eassy': 'Human civilization has always advanced on the pillars of innovation. From the discovery of fire to the invention of the wheel, from industrial machinery to artificial intelligence, technology has consistently shaped the trajectory of human progress. Yet, every leap forward has confronted humanity with new moral dilemmas. Today, as the world enters an era defined by artificial intelligence, biotechnology, quantum computing, and space exploration, the gap between what humanity can do and what it should do has never been wider. The future of humanity will not be determined solely by the pace of technological progress, but by our ability to anchor that progress in ethical responsibility.',\n",
       " 'cot_score': 9.5,\n",
       " 'depth_of_analysis_score': 8.5,\n",
       " 'language_proficiency_score': 10.0,\n",
       " 'average_score': 9.333333333333334}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d59b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
